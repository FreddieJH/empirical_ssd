{
  "hash": "4a794191d4bcdcd03cd3d4df32fd4b51",
  "result": {
    "markdown": "---\ntitle: \"Data cleaning\"\neditor: visual\nauthor: Freddie Heather\ndate: \"23 March, 2023\"\n---\n\n\n\n\n# Set-up\n\n### Required packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(ggExtra, include.only = \"ggMarginal\")\nlibrary(cowplot)\nlibrary(rvest)\nlibrary(magick)\nlibrary(EnvStats, include.only = \"rosnerTest\")\nlibrary(ozmaps)\nlibrary(CoordinateCleaner, include.only = \"cc_outl\")\n```\n:::\n\n\n# Raw data import\n\n## About the data\n\nThe raw data comes from the Reef Life survey dropbox folder. I downloaded only Method 1 data:\n\n-   fish only (non-cryptic species)\n\n-   50m transect line\n\n-   2x blocks, each side of the transect, each block 5m wide\n\n-   total = 50x10 = 500$m^2$ area\n\nI saved this file locally and it is named `ep_m1_ALL.csv`.\n\nFirst I got the observational level data, the minimum required columns were:\n\n| survey_id | species_name | size_class |\n|-----------|--------------|------------|\n| survey_A  | species_A    | 2.5        |\n| survey_A  | species_A    | 2.5        |\n| survey_A  | species_B    | 7.5        |\n\nEach row corresponds to a single fish individual.\n\n## Reading in the raw data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Observation level data (survey_id, species_name, size)\nif(!file.exists(\"data/cleaned/obs_data_m1_aus.parquet\")){\n  read_csv(\"data/raw/ep_m1_ALL.csv\") %>% \n    filter(country == \"Australia\") %>% \n    filter(method == 1) %>% \n    filter(size_class > 0) %>% \n    mutate(species_name = str_remove(species_name, \"/fucicola hybrid\")) |>\n    group_by(\n      survey_id, \n      species_name,\n      size_class\n    ) %>% \n    summarise(total = sum(total),\n              .groups = \"drop\") %>% \n    uncount(weights = total) %>% \n    filter(str_detect(species_name, \"[A-Z]{1}[a-z]+\\\\s[a-z]+\")) %>% \n    filter(!str_detect(species_name, \"\\\\.\")) %>% \n    write_parquet(\"data/cleaned/obs_data_m1_aus.parquet\")\n}\n\ndat_obs <- \n  \"data/cleaned/obs_data_m1_aus.parquet\" |> \n  read_parquet()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_obs |> \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 3\n  survey_id species_name          size_class\n      <dbl> <chr>                      <dbl>\n1   2000854 Achoerodus viridis          50  \n2   2000854 Achoerodus viridis          62.5\n3   2000854 Achoerodus viridis         112. \n4   2000854 Aplodactylus lophodon       15  \n5   2000854 Aplodactylus lophodon       20  \n6   2000854 Atypichthys strigatus        2.5\n```\n:::\n:::\n\n\n## Creating ID tables\n\nI need a table to link the `survey_id` to the other location information, such as the site name, the latitude and longitude of the site, the date of the survey and the depth of the survey. `dat_surv` will contain all of the survey-level data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# survey-level data (survey_id, site_code, lat, lon etc.)\nif(!file.exists(\"data/cleaned/survey_list_m1_aus.parquet\")){\n  read_csv(\"data/raw/ep_m1_ALL.csv\") %>% \n    filter(country == \"Australia\") %>% \n    select(\n      survey_id,\n      site_code,\n      ecoregion, \n      latitude, \n      longitude, \n      depth, \n      survey_date\n    ) %>% \n    distinct() %>%\n    mutate(survey_year = year(survey_date) |> as.integer()) |> \n    write_parquet(\"data/cleaned/survey_list_m1_aus.parquet\")\n  \n}\n\ndat_surv <- \n  \"data/cleaned/survey_list_m1_aus.parquet\" |> \n  read_parquet()\n```\n:::\n\n\n## Raw data summary\n\nTop 6 rows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_surv |> \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 8\n  survey_id site_code ecoregion         latit~1 longi~2 depth survey_d~3 surve~4\n      <dbl> <chr>     <chr>               <dbl>   <dbl> <dbl> <date>       <int>\n1 923401360 GSV53     South Australian~   -35.2    138.   6.1 2022-09-01    2022\n2 923401359 GSV138    South Australian~   -35.2    138.   6.2 2022-09-01    2022\n3 923401358 GSV131    South Australian~   -35.1    138.  12.1 2022-09-01    2022\n4 923401357 GSV140    South Australian~   -35.1    138.   5.1 2022-03-23    2022\n5 923401356 GSV139    South Australian~   -35.1    138.   3.2 2022-03-25    2022\n6 923401355 GSV135    South Australian~   -35.1    138.   3.2 2022-08-31    2022\n# ... with abbreviated variable names 1: latitude, 2: longitude,\n#   3: survey_date, 4: survey_year\n```\n:::\n:::\n\n\nNumbers:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_surv |> pull(site_code) |> unique() |> length() |> paste(\"sites\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2604 sites\"\n```\n:::\n\n```{.r .cell-code}\ndat_surv |> pull(ecoregion) |> unique() |> length() |> paste(\"ecoregions\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"20 ecoregions\"\n```\n:::\n\n```{.r .cell-code}\ndat_obs |> pull(species_name) |> unique() |> length() |> paste(\"species\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"1645 species\"\n```\n:::\n:::\n\n\n# Raw data visualisation\n\nThese are the functions used to create the plots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadd_density_margin <- function(ggplot_obj) {\n  ggExtra::ggMarginal(ggplot_obj, \"density\", margins = \"y\", linewidth = 2)\n}\n\n\nplot_spp_timeseries <- function(spp_name){\n  \n  size_byyear <-\n    dat_full |> \n    filter(species_name == spp_name) \n  \n  meansize_byyear <-\n    size_byyear |> \n    summarise(mean_size = mean(size_class), \n              .by = c(survey_year))\n  \n  n_indiv <- \n    nrow(size_byyear) |> \n    as.numeric() |> \n    round(1) |> \n    format(nsmall = 0, \n           big.mark = \",\")\n  \n  size_byyear |> \n    count(species_name, survey_year, size_class) |> \n    ggplot() +\n    aes(\n      x = survey_year, \n      y = size_class\n    ) +\n    geom_point(aes(size = n), \n               colour = \"grey90\") +\n    geom_point(aes(y = mean_size), data = meansize_byyear) +\n    geom_line(aes(y = mean_size), data = meansize_byyear) +\n    labs(\n      x = \"Year\", \n      y = \"Mean size\", \n      title = paste0(spp_name, \" (n = \", n_indiv, \")\"),\n      size = \"# individuals\"\n    ) +\n    scale_y_continuous(labels = label_number(suffix = \"cm\", accuracy = 1)) +\n    theme_cowplot() +\n    theme(plot.title = element_text(hjust = 0.5),\n          legend.position = c(0.005,1), \n          legend.justification = c(0,1))\n}\n\nplot_spp_timeseries_withmargin <- function(spp_name){\n  plot_spp_timeseries(spp_name) |> \n  add_density_margin()\n}\n```\n:::\n\n\n## Species body size distributions (SSDs)\n\nWe'll start by randomly selecting 20 species. Let's plot the data for the species across all of time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\nrandom_selection_spp <- \n  dat_obs |> \n  pull(species_name) |> \n  unique() |> \n  sample(20)\n\n\ndat_obs |> \n  filter(species_name %in% random_selection_spp) |> \n  count(species_name, size_class) |> \n  ggplot() +\n  aes(\n    x = size_class,\n    y = n\n  ) + \n  geom_point() +\n  geom_line() +\n  facet_wrap(~species_name, scales = \"free\")\n```\n\n::: {.cell-output-display}\n![](data_cleaning_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nIt's clear that some species are not worth including, for example *Bothus pantherinus* has a count of 2, and is observed only in one size class (20cm). We therefore should have some lower bounds of data requirements.\n\n# Raw data filtering\n\nFirstly, the species should cover at least three body size classes, otherwise distribution fitting will be quite difficult.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1274 species\ndat_spp_filter_sizeclasses <- \n  dat_obs |> \n  select(species_name, size_class) |> \n  distinct() |> \n  count(species_name) |> \n  filter(n >= 3) |>  \n  pull(species_name)\n\n# removing species that have less than 3 body size classes\ndat_obs_f1 <- \n  dat_obs |> \n  filter(species_name %in% dat_spp_filter_sizeclasses)\n```\n:::\n\n\nIt's also worth having a minimum number of total observations for a species. Let's have a look at the density distribution of total abundances for each.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_obs_f1 |> \n  count(species_name) |> \n  ggplot() +\n  aes(\n    x = n \n  ) + \n  geom_density() +\n  labs(x = \"Species total observations\",\n       y = \"Probability density\", \n       caption = \"Dotted vertical line at 200 individuals within a species\") +\n  scale_x_continuous(trans = \"log10\", label = label_number()) +\n  geom_vline(xintercept = 200, lty = 2)\n```\n\n::: {.cell-output-display}\n![](data_cleaning_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nThere is a peak in total species abundance at around 200 individuals, which seems like a reasonable cut-off to use.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 776 species\ndat_spp_filter_totaln <- \n  dat_obs_f1 |> \n  count(species_name) |> \n  filter(n >= 200) |> \n  pull(species_name)\n\n# removing species that have less than 200 total observations\ndat_obs_f2 <- \n  dat_obs_f1 |> \n  filter(species_name %in% dat_spp_filter_totaln)\n```\n:::\n\n\nWe now have a subset (n = 776 species) of the total dataset (n = 1646 species).\n\n# Error checking\n\nIn such a large dataset, there are bound to be errors in body size estimates or species identification.\n\n## Errors in body size\n\n### Visualising errors in body size\n\nOne way to do this, would be to look at the univariate body size distribution of each species and identify potential outliers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor(i in unique(dat_obs_f2$species_name)){\n  file_name <- paste0(\"output/figs/error_checking/bodysize/ssd/\", \n                      i, \n                      \".png\")\n  \n  \n  if(!file.exists(file_name)){\n    \n    p <- \n      dat_obs_f2 |> \n      filter(species_name == i) |> \n      count(size_class) |> \n      ggplot() +\n      aes(\n        x = size_class, \n        y = n\n      ) +\n      geom_point() +\n      geom_line() +\n      scale_y_continuous(trans = \"log10\", \n                         label = label_number(scale_cut = cut_short_scale())) +\n      scale_x_continuous(label = label_number(suffix = \"cm\")) +\n      labs(x = \"Body size class\",\n           y = \"Count (log scale)\") +\n      theme_cowplot() \n    \n    ggsave(filename = file_name,\n      plot = p,\n       height = 8, \n      width = 16, \n      units = \"cm\")\n  }\n}\n```\n:::\n\n\nLet's look at just one of those species size distributions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfile_name |> \n  include_graphics()\n```\n\n::: {.cell-output-display}\n![](output/figs/error_checking/bodysize/ssd/Kyphosus gladius.png){width=944}\n:::\n:::\n\n\nIn some cases it is obvious that there are some outliers (see *Halichoeres biocellatus*).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\"output/figs/error_checking/bodysize/ssd/Halichoeres biocellatus.png\" |> \n  include_graphics()\n```\n\n::: {.cell-output-display}\n![](output/figs/error_checking/bodysize/ssd/Halichoeres biocellatus.png){width=944}\n:::\n:::\n\n\n### Detection of errors in body size\n\nI played around with Z-transformation, but i found the best method of estimating outliers was using the Rosner's test. I decided to use the Rosner's test on the log(body size) instead of body size as this better accounts for the normality assumption of the Rosner's test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndetect_outliers <- function(size_vec, logvals = TRUE){\n  \n  \n    if(logvals){\n      vec <- log(size_vec)\n    } else {\n      vec <- size_vec\n    }\n  \n  # rosnerTest doesn't like more than 10 potential outliers\n  nn <- ifelse(length(unique(vec)) > 10, 10, length(unique(vec)))\n  \n  if(length(unique(vec)) > 3) {\n    out <- \n      vec |>  \n      EnvStats::rosnerTest(k = nn) |> \n      pluck(\"all.stats\") |> \n      as_tibble() |> \n      filter(Outlier) |> \n      pull(Value)\n    \n    vec %in% out\n  } else {\n    rep(FALSE, length(vec))\n  }\n\n}\n```\n:::\n\n\nWe want to only look at body sizes that are greater than the mean body size of the species, i.e. we don't care about outliers on the smaller body size end, as these could quite plausibly be juveniles of the species, therefore difficult to definitively determine to be an outlier.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspp_meansizes <- \n  dat_obs_f2 |> \n  group_by(species_name) |> \n  mutate(spp_meansize = mean(size_class)) |> \n  select(species_name, \n         spp_meansize) |> \n  distinct()\n\n# 89 species that may have oversized estimates\nrosner_outliers <- \n  dat_obs_f2 |> \n  group_by(species_name) |> \n  mutate(is_outlier = detect_outliers(size_class, logvals = TRUE)) |> \n  filter(is_outlier) |> \n  left_join(spp_meansizes, join_by(species_name)) |> \n  filter(size_class > spp_meansize) |> \n  count(species_name, size_class)\n\ndat_obs_f2_hasoutliers <-\n  dat_obs_f2 |> \n  filter(species_name %in% rosner_outliers$species_name)\n\n\nfor(i in unique(dat_obs_f2_hasoutliers$species_name)){\n  file_name <- paste0(\"output/figs/error_checking/bodysize/ssd/highlighting_outliers/\", \n                      i, \n                      \".png\")\n  \n  \n  if(!file.exists(file_name)){\n    \n    p <- \n      dat_obs_f2_hasoutliers |> \n      filter(species_name == i) |> \n      count(size_class) |> \n      ggplot() +\n      aes(\n        x = size_class, \n        y = n\n      ) +\n      geom_point() +\n      geom_line() +\n      geom_point(data = \n                   rosner_outliers |> \n      filter(species_name == i), \n                 pch = 21,\n                 stroke = 2,\n      size = 4,\n                 colour = \"red\") +\n      scale_y_continuous(trans = \"log10\") +\n      scale_x_continuous(label = label_number(suffix = \"cm\")) +\n      labs(x = \"Body size class\",\n           y = \"Count (log scale)\") +\n      theme_cowplot() \n    \n    ggsave(filename = file_name,\n      plot = p,\n       height = 8, \n      width = 16, \n      units = \"cm\")\n  }\n}\n```\n:::\n\n\nOf these, I would say only a handful of them are actually outliers. I will then take those and look at the most extreme Z-transformed scores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nztrans_outliers <- \n  dat_obs_f2_hasoutliers |>\n  group_by(species_name) |> \n  mutate(size_class_z = scale(size_class) |> as.numeric()) |> \n  filter(size_class_z > 20) |> \n  count(species_name, size_class)\n\n\ndat_obs_f2_hasoutliers_extreme <-\n  dat_obs_f2 |> \n  filter(species_name %in% ztrans_outliers$species_name)\n\n\nfor(i in unique(dat_obs_f2_hasoutliers_extreme$species_name)){\n  file_name <- paste0(\"output/figs/error_checking/bodysize/ssd/highlighting_outliers/extreme/\", \n                      i, \n                      \".png\")\n  \n  \n  if(!file.exists(file_name)){\n    \n    p <- \n      dat_obs_f2_hasoutliers_extreme |> \n      filter(species_name == i) |> \n      count(size_class) |> \n      ggplot() +\n      aes(\n        x = size_class, \n        y = n\n      ) +\n      geom_point() +\n      geom_line() +\n      geom_point(data = \n                   ztrans_outliers |> \n      filter(species_name == i), \n                 pch = 21,\n                 stroke = 2,\n      size = 4,\n                 colour = \"red\") +\n      scale_y_continuous(trans = \"log10\") +\n      scale_x_continuous(label = label_number(suffix = \"cm\")) +\n      labs(x = \"Body size class\",\n           y = \"Count (log scale)\") +\n      theme_cowplot() \n    \n    ggsave(filename = file_name,\n      plot = p,\n       height = 8, \n      width = 16, \n      units = \"cm\")\n  }\n}\n```\n:::\n\n\nI have gotten it down to 25 species with potential body size errors.\n\n### Removing body size outliers\n\nI think that most of these should be removed, except for the species *Parma victoriae* which looks bimodal, *Ostorhinchus neotes* and *Pomacentrus bankanensis* which could are plausible body sizes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremoval_table <-\n  ztrans_outliers |> \n  filter(!(species_name %in% c(\"Parma victoriae\", \n                              \"Ostorhinchus neotes\",\n                              \"Pomacentrus bankanensis\"))) |> \n  select(species_name, size_class) |> \n  mutate(extreme_outlier = TRUE) |> \n  ungroup()\n\n\ndat_obs_f3 <-\n  dat_obs_f2 |> \n  left_join(removal_table) |> \n  filter(is.na(extreme_outlier)) |> \n  select(-extreme_outlier)\n```\n:::\n\n\n## Errors in location\n\n### Visualising geographic distributions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# \n# for(i in unique(dat_obs_f3$species_name)){\n# \n#   file_name <- paste0(\"output/figs/error_checking/geography/\",\n#                       i,\n#                       \".png\")\n#   if(!file.exists(file_name)){\n# \n#     plot_dat <-\n#       dat_obs_f3 |>\n#       filter(species_name == i) |>\n#       left_join(dat_surv) |> \n#       count(species_name, latitude, longitude)\n# \n#     map_plot <-\n#       ozmap(x = \"country\") |>\n#       ggplot() +\n#       geom_sf() +\n#       coord_sf() +\n#       geom_point(\n#         aes(\n#           x = longitude,\n#           y = latitude,\n#           size = n\n#         ),\n#         pch = 21,\n#         col = \"red\",\n#         data = plot_dat\n#       ) +\n#       scale_size_continuous(name = \"# individuals\",\n#                             trans = \"log10\",\n#                             label = label_number(scale_cut = cut_short_scale())) +\n# \n#       theme_void() +\n#       theme(legend.position = c(0.3, 0.5),\n#             legend.justification = c(0.5, 0.5),\n#             plot.title = element_text(hjust = 0.5))\n# \n#     n_indiv <-\n#       sum(plot_dat$n) |>\n#       as.numeric() |>\n#       round(1) |>\n#       format(nsmall = 0,\n#              big.mark = \",\")\n# \n#     url_vector <-\n#       paste0(\"https://reeflifesurvey.com//species/\", \n#              i |> \n#              tolower() |> \n#              str_replace_all(\" \", \"-\")) |>\n#       read_html() |>\n#       html_elements(\"img\") |>\n#       html_attr(\"src\")\n# \n#     if(sum(url_vector |> str_detect(\"species_\"))){\n#       hasimage <- 1\n#       myimage <-\n#         url_vector[url_vector |> str_detect(\"species_\")][1] |>\n#         image_read()\n#     } else {\n#       hasimage <- 0\n#     }\n# \n#     basic_plot <- map_plot\n# \n#     xrange <- layer_scales(basic_plot)$x$range$range\n#     yrange <- layer_scales(basic_plot)$y$range$range\n# \n#     p2 <-\n#       map_plot +\n#       labs(caption = \"Geographic species distribution\",\n#            title = paste0(i, \" (n = \", n_indiv, \")\")) +\n#       {if(hasimage)      annotation_raster(myimage,\n#                                            xrange[2]-((xrange[2]-xrange[1])*0.2)- (xrange[2]-xrange[1])*.35,\n#                                            xrange[2]- (xrange[2]-xrange[1])*.35,\n#                                            yrange[2]-((yrange[2]-yrange[1])*0.2)- (yrange[2]-yrange[1])*.4,\n#                                            yrange[2] - (yrange[2]-yrange[1])*.4)}\n# \n# \n# \n# \n#     ggsave(filename = file_name,\n#            plot = add_density_margin(p2),\n#            height = 15,\n#            width = 30,\n#            units = \"cm\")\n# \n# \n#   }\n# }\n```\n:::\n\n\n### Detecting geographic outliers\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfile_name <- \"output/data/error_checking/geography/geog_outliers.csv\"\n\nif(!file.exists(file_name)){\n\nvals <-\n  dat_obs_f3 |>\n  left_join(dat_surv) |> \n  rename(species = species_name,\n          decimallongitude = longitude,\n          decimallatitude = latitude) |>\n  CoordinateCleaner::cc_outl(value = \"flagged\")\n\n  dat_obs_f3 |>\n    left_join(dat_surv) |>\n    mutate(good_geog = vals) |>\n    write_csv(file_name)\n}\n\nfile_name |> read_csv()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15,050,191 x 11\n   survey_id species_~1 size_~2 site_~3 ecore~4 latit~5 longi~6 depth survey_d~7\n       <dbl> <chr>        <dbl> <chr>   <chr>     <dbl>   <dbl> <dbl> <date>    \n 1   2000854 Achoerodu~    50   SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 2   2000854 Achoerodu~    62.5 SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 3   2000854 Achoerodu~   112.  SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 4   2000854 Aplodacty~    15   SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 5   2000854 Aplodacty~    20   SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 6   2000854 Atypichth~     2.5 SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 7   2000854 Atypichth~     2.5 SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 8   2000854 Atypichth~     2.5 SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 9   2000854 Atypichth~     2.5 SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n10   2000854 Atypichth~     2.5 SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n# ... with 15,050,181 more rows, 2 more variables: survey_year <dbl>,\n#   good_geog <lgl>, and abbreviated variable names 1: species_name,\n#   2: size_class, 3: site_code, 4: ecoregion, 5: latitude, 6: longitude,\n#   7: survey_date\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngeog_outliers <- \n  \"output/data/error_checking/geography/geog_outliers.csv\" |> \n  read_csv() |> \n  filter(!good_geog) |> \n  mutate(spp_lat_lon = paste(species_name, \n                              latitude, \n                              longitude, \n                              sep = \"_\"))\n\ndat_obs_f3_hasgeogoutliers <- \n  dat_obs_f3 |> \n  left_join(dat_surv) |> \n  mutate(spp_lat_lon = paste(species_name, \n                              latitude, \n                              longitude, \n                              sep = \"_\")) |> \n  filter(spp_lat_lon %in% geog_outliers$spp_lat_lon) |> \n  select(-spp_lat_lon) |> \n  left_join(geog_outliers |> \n              select(species_name, \n                     latitude, \n                     longitude) |> \n              mutate(geog_outlier = TRUE))\n\n\n\nfor(i in unique(dat_obs_f3_hasgeogoutliers$species_name)){\n\n  file_name <- paste0(\"output/figs/error_checking/geography/\",\n                      i,\n                      \".png\")\n  if(!file.exists(file_name)){\n\n    plot_dat <-\n      dat_obs_f3 |>\n      filter(species_name == i) |>\n      left_join(dat_surv) |>\n      count(species_name, latitude, longitude)\n\n    map_plot <-\n      ozmap(x = \"country\") |>\n      ggplot() +\n      geom_sf() +\n      coord_sf() +\n      geom_point(\n        aes(\n          x = longitude,\n          y = latitude,\n          size = n\n        ),\n        pch = 21,\n        col = \"red\",\n        data = plot_dat\n      ) +\n      scale_size_continuous(name = \"# individuals\",\n                            trans = \"log10\",\n                            label = label_number(scale_cut = cut_short_scale())) +\n\n      theme_void() +\n      theme(legend.position = c(0.3, 0.5),\n            legend.justification = c(0.5, 0.5),\n            plot.title = element_text(hjust = 0.5))\n\n    n_indiv <-\n      sum(plot_dat$n) |>\n      as.numeric() |>\n      round(1) |>\n      format(nsmall = 0,\n             big.mark = \",\")\n\n    url_vector <-\n      paste0(\"https://reeflifesurvey.com//species/\",\n             i |>\n             tolower() |>\n             str_replace_all(\" \", \"-\")) |>\n      read_html() |>\n      html_elements(\"img\") |>\n      html_attr(\"src\")\n\n    if(sum(url_vector |> str_detect(\"species_\"))){\n      hasimage <- 1\n      myimage <-\n        url_vector[url_vector |> str_detect(\"species_\")][1] |>\n        image_read()\n    } else {\n      hasimage <- 0\n    }\n\n    basic_plot <- map_plot\n\n    xrange <- layer_scales(basic_plot)$x$range$range\n    yrange <- layer_scales(basic_plot)$y$range$range\n\n    p2 <-\n      map_plot +\n      labs(caption = \"Geographic species distribution\",\n           title = paste0(i, \" (n = \", n_indiv, \")\")) +\n      {if(hasimage)      annotation_raster(myimage,\n                                           xrange[2]-((xrange[2]-xrange[1])*0.2)- (xrange[2]-xrange[1])*.35,\n                                           xrange[2]- (xrange[2]-xrange[1])*.35,\n                                           yrange[2]-((yrange[2]-yrange[1])*0.2)- (yrange[2]-yrange[1])*.4,\n                                           yrange[2] - (yrange[2]-yrange[1])*.4)}\n\n    ggsave(filename = file_name,\n           plot = add_density_margin(p2),\n           height = 15,\n           width = 30,\n           units = \"cm\")\n\n\n  }\n}\n```\n:::\n",
    "supporting": [
      "data_cleaning_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}