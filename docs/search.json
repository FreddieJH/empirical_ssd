[
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "Data cleaning",
    "section": "",
    "text": "library(tidyverse)\nlibrary(arrow)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(ggExtra, include.only = \"ggMarginal\")\nlibrary(cowplot)\nlibrary(rvest)\nlibrary(magick)\nlibrary(EnvStats, include.only = \"rosnerTest\")\nlibrary(ozmaps)\nlibrary(CoordinateCleaner, include.only = \"cc_outl\")"
  },
  {
    "objectID": "data_cleaning.html#about-the-data",
    "href": "data_cleaning.html#about-the-data",
    "title": "Data cleaning",
    "section": "About the data",
    "text": "About the data\nThe raw data comes from the Reef Life survey dropbox folder. I downloaded only Method 1 data:\n\nfish only (non-cryptic species)\n50m transect line\n2x blocks, each side of the transect, each block 5m wide\ntotal = 50x10 = 500\\(m^2\\) area\n\nI saved this file locally and it is named ep_m1_ALL.csv.\nFirst I got the observational level data, the minimum required columns were:\n\n\n\nsurvey_id\nspecies_name\nsize_class\n\n\n\n\nsurvey_A\nspecies_A\n2.5\n\n\nsurvey_A\nspecies_A\n2.5\n\n\nsurvey_A\nspecies_B\n7.5\n\n\n\nEach row corresponds to a single fish individual."
  },
  {
    "objectID": "data_cleaning.html#reading-in-the-raw-data",
    "href": "data_cleaning.html#reading-in-the-raw-data",
    "title": "Data cleaning",
    "section": "Reading in the raw data",
    "text": "Reading in the raw data\n\n# Observation level data (survey_id, species_name, size)\nif(!file.exists(\"data/cleaned/obs_data_m1_aus.parquet\")){\n  read_csv(\"data/raw/ep_m1_ALL.csv\") %>% \n    filter(country == \"Australia\") %>% \n    filter(method == 1) %>% \n    filter(size_class > 0) %>% \n    mutate(species_name = str_remove(species_name, \"/fucicola hybrid\")) |>\n    group_by(\n      survey_id, \n      species_name,\n      size_class\n    ) %>% \n    summarise(total = sum(total),\n              .groups = \"drop\") %>% \n    uncount(weights = total) %>% \n    filter(str_detect(species_name, \"[A-Z]{1}[a-z]+\\\\s[a-z]+\")) %>% \n    filter(!str_detect(species_name, \"\\\\.\")) %>% \n    write_parquet(\"data/cleaned/obs_data_m1_aus.parquet\")\n}\n\ndat_obs <- \n  \"data/cleaned/obs_data_m1_aus.parquet\" |> \n  read_parquet()\n\n\ndat_obs |> \n  head()\n\n# A tibble: 6 x 3\n  survey_id species_name          size_class\n      <dbl> <chr>                      <dbl>\n1   2000854 Achoerodus viridis          50  \n2   2000854 Achoerodus viridis          62.5\n3   2000854 Achoerodus viridis         112. \n4   2000854 Aplodactylus lophodon       15  \n5   2000854 Aplodactylus lophodon       20  \n6   2000854 Atypichthys strigatus        2.5"
  },
  {
    "objectID": "data_cleaning.html#creating-id-tables",
    "href": "data_cleaning.html#creating-id-tables",
    "title": "Data cleaning",
    "section": "Creating ID tables",
    "text": "Creating ID tables\nI need a table to link the survey_id to the other location information, such as the site name, the latitude and longitude of the site, the date of the survey and the depth of the survey. dat_surv will contain all of the survey-level data.\n\n# survey-level data (survey_id, site_code, lat, lon etc.)\nif(!file.exists(\"data/cleaned/survey_list_m1_aus.parquet\")){\n  read_csv(\"data/raw/ep_m1_ALL.csv\") %>% \n    filter(country == \"Australia\") %>% \n    select(\n      survey_id,\n      site_code,\n      ecoregion, \n      latitude, \n      longitude, \n      depth, \n      survey_date\n    ) %>% \n    distinct() %>%\n    mutate(survey_year = year(survey_date) |> as.integer()) |> \n    write_parquet(\"data/cleaned/survey_list_m1_aus.parquet\")\n  \n}\n\ndat_surv <- \n  \"data/cleaned/survey_list_m1_aus.parquet\" |> \n  read_parquet()"
  },
  {
    "objectID": "data_cleaning.html#raw-data-summary",
    "href": "data_cleaning.html#raw-data-summary",
    "title": "Data cleaning",
    "section": "Raw data summary",
    "text": "Raw data summary\nTop 6 rows:\n\ndat_surv |> \n  head()\n\n# A tibble: 6 x 8\n  survey_id site_code ecoregion         latit~1 longi~2 depth survey_d~3 surve~4\n      <dbl> <chr>     <chr>               <dbl>   <dbl> <dbl> <date>       <int>\n1 923401360 GSV53     South Australian~   -35.2    138.   6.1 2022-09-01    2022\n2 923401359 GSV138    South Australian~   -35.2    138.   6.2 2022-09-01    2022\n3 923401358 GSV131    South Australian~   -35.1    138.  12.1 2022-09-01    2022\n4 923401357 GSV140    South Australian~   -35.1    138.   5.1 2022-03-23    2022\n5 923401356 GSV139    South Australian~   -35.1    138.   3.2 2022-03-25    2022\n6 923401355 GSV135    South Australian~   -35.1    138.   3.2 2022-08-31    2022\n# ... with abbreviated variable names 1: latitude, 2: longitude,\n#   3: survey_date, 4: survey_year\n\n\nNumbers:\n\ndat_surv |> pull(site_code) |> unique() |> length() |> paste(\"sites\")\n\n[1] \"2604 sites\"\n\ndat_surv |> pull(ecoregion) |> unique() |> length() |> paste(\"ecoregions\")\n\n[1] \"20 ecoregions\"\n\ndat_obs |> pull(species_name) |> unique() |> length() |> paste(\"species\")\n\n[1] \"1645 species\""
  },
  {
    "objectID": "data_cleaning.html#species-body-size-distributions-ssds",
    "href": "data_cleaning.html#species-body-size-distributions-ssds",
    "title": "Data cleaning",
    "section": "Species body size distributions (SSDs)",
    "text": "Species body size distributions (SSDs)\nWe’ll start by randomly selecting 20 species. Let’s plot the data for the species across all of time.\n\nset.seed(1)\nrandom_selection_spp <- \n  dat_obs |> \n  pull(species_name) |> \n  unique() |> \n  sample(20)\n\n\ndat_obs |> \n  filter(species_name %in% random_selection_spp) |> \n  count(species_name, size_class) |> \n  ggplot() +\n  aes(\n    x = size_class,\n    y = n\n  ) + \n  geom_point() +\n  geom_line() +\n  facet_wrap(~species_name, scales = \"free\")\n\n\n\n\nIt’s clear that some species are not worth including, for example Bothus pantherinus has a count of 2, and is observed only in one size class (20cm). We therefore should have some lower bounds of data requirements."
  },
  {
    "objectID": "data_cleaning.html#errors-in-body-size",
    "href": "data_cleaning.html#errors-in-body-size",
    "title": "Data cleaning",
    "section": "Errors in body size",
    "text": "Errors in body size\n\nVisualising errors in body size\nOne way to do this, would be to look at the univariate body size distribution of each species and identify potential outliers.\n\nfor(i in unique(dat_obs_f2$species_name)){\n  file_name <- paste0(\"output/figs/error_checking/bodysize/ssd/\", \n                      i, \n                      \".png\")\n  \n  \n  if(!file.exists(file_name)){\n    \n    p <- \n      dat_obs_f2 |> \n      filter(species_name == i) |> \n      count(size_class) |> \n      ggplot() +\n      aes(\n        x = size_class, \n        y = n\n      ) +\n      geom_point() +\n      geom_line() +\n      scale_y_continuous(trans = \"log10\", \n                         label = label_number(scale_cut = cut_short_scale())) +\n      scale_x_continuous(label = label_number(suffix = \"cm\")) +\n      labs(x = \"Body size class\",\n           y = \"Count (log scale)\") +\n      theme_cowplot() \n    \n    ggsave(filename = file_name,\n      plot = p,\n       height = 8, \n      width = 16, \n      units = \"cm\")\n  }\n}\n\nLet’s look at just one of those species size distributions:\n\nfile_name |> \n  include_graphics()\n\n\n\n\nIn some cases it is obvious that there are some outliers (see Halichoeres biocellatus).\n\n\"output/figs/error_checking/bodysize/ssd/Halichoeres biocellatus.png\" |> \n  include_graphics()\n\n\n\n\n\n\nDetection of errors in body size\nI played around with Z-transformation, but i found the best method of estimating outliers was using the Rosner’s test. I decided to use the Rosner’s test on the log(body size) instead of body size as this better accounts for the normality assumption of the Rosner’s test.\n\ndetect_outliers <- function(size_vec, logvals = TRUE){\n  \n  \n    if(logvals){\n      vec <- log(size_vec)\n    } else {\n      vec <- size_vec\n    }\n  \n  # rosnerTest doesn't like more than 10 potential outliers\n  nn <- ifelse(length(unique(vec)) > 10, 10, length(unique(vec)))\n  \n  if(length(unique(vec)) > 3) {\n    out <- \n      vec |>  \n      EnvStats::rosnerTest(k = nn) |> \n      pluck(\"all.stats\") |> \n      as_tibble() |> \n      filter(Outlier) |> \n      pull(Value)\n    \n    vec %in% out\n  } else {\n    rep(FALSE, length(vec))\n  }\n\n}\n\nWe want to only look at body sizes that are greater than the mean body size of the species, i.e. we don’t care about outliers on the smaller body size end, as these could quite plausibly be juveniles of the species, therefore difficult to definitively determine to be an outlier.\n\nspp_meansizes <- \n  dat_obs_f2 |> \n  group_by(species_name) |> \n  mutate(spp_meansize = mean(size_class)) |> \n  select(species_name, \n         spp_meansize) |> \n  distinct()\n\n# 89 species that may have oversized estimates\nrosner_outliers <- \n  dat_obs_f2 |> \n  group_by(species_name) |> \n  mutate(is_outlier = detect_outliers(size_class, logvals = TRUE)) |> \n  filter(is_outlier) |> \n  left_join(spp_meansizes, join_by(species_name)) |> \n  filter(size_class > spp_meansize) |> \n  count(species_name, size_class)\n\ndat_obs_f2_hasoutliers <-\n  dat_obs_f2 |> \n  filter(species_name %in% rosner_outliers$species_name)\n\n\nfor(i in unique(dat_obs_f2_hasoutliers$species_name)){\n  file_name <- paste0(\"output/figs/error_checking/bodysize/ssd/highlighting_outliers/\", \n                      i, \n                      \".png\")\n  \n  \n  if(!file.exists(file_name)){\n    \n    p <- \n      dat_obs_f2_hasoutliers |> \n      filter(species_name == i) |> \n      count(size_class) |> \n      ggplot() +\n      aes(\n        x = size_class, \n        y = n\n      ) +\n      geom_point() +\n      geom_line() +\n      geom_point(data = \n                   rosner_outliers |> \n      filter(species_name == i), \n                 pch = 21,\n                 stroke = 2,\n      size = 4,\n                 colour = \"red\") +\n      scale_y_continuous(trans = \"log10\") +\n      scale_x_continuous(label = label_number(suffix = \"cm\")) +\n      labs(x = \"Body size class\",\n           y = \"Count (log scale)\") +\n      theme_cowplot() \n    \n    ggsave(filename = file_name,\n      plot = p,\n       height = 8, \n      width = 16, \n      units = \"cm\")\n  }\n}\n\nOf these, I would say only a handful of them are actually outliers. I will then take those and look at the most extreme Z-transformed scores.\n\nztrans_outliers <- \n  dat_obs_f2_hasoutliers |>\n  group_by(species_name) |> \n  mutate(size_class_z = scale(size_class) |> as.numeric()) |> \n  filter(size_class_z > 20) |> \n  count(species_name, size_class)\n\n\ndat_obs_f2_hasoutliers_extreme <-\n  dat_obs_f2 |> \n  filter(species_name %in% ztrans_outliers$species_name)\n\n\nfor(i in unique(dat_obs_f2_hasoutliers_extreme$species_name)){\n  file_name <- paste0(\"output/figs/error_checking/bodysize/ssd/highlighting_outliers/extreme/\", \n                      i, \n                      \".png\")\n  \n  \n  if(!file.exists(file_name)){\n    \n    p <- \n      dat_obs_f2_hasoutliers_extreme |> \n      filter(species_name == i) |> \n      count(size_class) |> \n      ggplot() +\n      aes(\n        x = size_class, \n        y = n\n      ) +\n      geom_point() +\n      geom_line() +\n      geom_point(data = \n                   ztrans_outliers |> \n      filter(species_name == i), \n                 pch = 21,\n                 stroke = 2,\n      size = 4,\n                 colour = \"red\") +\n      scale_y_continuous(trans = \"log10\") +\n      scale_x_continuous(label = label_number(suffix = \"cm\")) +\n      labs(x = \"Body size class\",\n           y = \"Count (log scale)\") +\n      theme_cowplot() \n    \n    ggsave(filename = file_name,\n      plot = p,\n       height = 8, \n      width = 16, \n      units = \"cm\")\n  }\n}\n\nI have gotten it down to 25 species with potential body size errors.\n\n\nRemoving body size outliers\nI think that most of these should be removed, except for the species Parma victoriae which looks bimodal, Ostorhinchus neotes and Pomacentrus bankanensis which could are plausible body sizes.\n\nremoval_table <-\n  ztrans_outliers |> \n  filter(!(species_name %in% c(\"Parma victoriae\", \n                              \"Ostorhinchus neotes\",\n                              \"Pomacentrus bankanensis\"))) |> \n  select(species_name, size_class) |> \n  mutate(extreme_outlier = TRUE) |> \n  ungroup()\n\n\ndat_obs_f3 <-\n  dat_obs_f2 |> \n  left_join(removal_table) |> \n  filter(is.na(extreme_outlier)) |> \n  select(-extreme_outlier)"
  },
  {
    "objectID": "data_cleaning.html#errors-in-location",
    "href": "data_cleaning.html#errors-in-location",
    "title": "Data cleaning",
    "section": "Errors in location",
    "text": "Errors in location\n\nVisualising geographic distributions\n\n# \n# for(i in unique(dat_obs_f3$species_name)){\n# \n#   file_name <- paste0(\"output/figs/error_checking/geography/\",\n#                       i,\n#                       \".png\")\n#   if(!file.exists(file_name)){\n# \n#     plot_dat <-\n#       dat_obs_f3 |>\n#       filter(species_name == i) |>\n#       left_join(dat_surv) |> \n#       count(species_name, latitude, longitude)\n# \n#     map_plot <-\n#       ozmap(x = \"country\") |>\n#       ggplot() +\n#       geom_sf() +\n#       coord_sf() +\n#       geom_point(\n#         aes(\n#           x = longitude,\n#           y = latitude,\n#           size = n\n#         ),\n#         pch = 21,\n#         col = \"red\",\n#         data = plot_dat\n#       ) +\n#       scale_size_continuous(name = \"# individuals\",\n#                             trans = \"log10\",\n#                             label = label_number(scale_cut = cut_short_scale())) +\n# \n#       theme_void() +\n#       theme(legend.position = c(0.3, 0.5),\n#             legend.justification = c(0.5, 0.5),\n#             plot.title = element_text(hjust = 0.5))\n# \n#     n_indiv <-\n#       sum(plot_dat$n) |>\n#       as.numeric() |>\n#       round(1) |>\n#       format(nsmall = 0,\n#              big.mark = \",\")\n# \n#     url_vector <-\n#       paste0(\"https://reeflifesurvey.com//species/\", \n#              i |> \n#              tolower() |> \n#              str_replace_all(\" \", \"-\")) |>\n#       read_html() |>\n#       html_elements(\"img\") |>\n#       html_attr(\"src\")\n# \n#     if(sum(url_vector |> str_detect(\"species_\"))){\n#       hasimage <- 1\n#       myimage <-\n#         url_vector[url_vector |> str_detect(\"species_\")][1] |>\n#         image_read()\n#     } else {\n#       hasimage <- 0\n#     }\n# \n#     basic_plot <- map_plot\n# \n#     xrange <- layer_scales(basic_plot)$x$range$range\n#     yrange <- layer_scales(basic_plot)$y$range$range\n# \n#     p2 <-\n#       map_plot +\n#       labs(caption = \"Geographic species distribution\",\n#            title = paste0(i, \" (n = \", n_indiv, \")\")) +\n#       {if(hasimage)      annotation_raster(myimage,\n#                                            xrange[2]-((xrange[2]-xrange[1])*0.2)- (xrange[2]-xrange[1])*.35,\n#                                            xrange[2]- (xrange[2]-xrange[1])*.35,\n#                                            yrange[2]-((yrange[2]-yrange[1])*0.2)- (yrange[2]-yrange[1])*.4,\n#                                            yrange[2] - (yrange[2]-yrange[1])*.4)}\n# \n# \n# \n# \n#     ggsave(filename = file_name,\n#            plot = add_density_margin(p2),\n#            height = 15,\n#            width = 30,\n#            units = \"cm\")\n# \n# \n#   }\n# }\n\n\n\nDetecting geographic outliers\n\nfile_name <- \"output/data/error_checking/geography/geog_outliers.csv\"\n\nif(!file.exists(file_name)){\n\nvals <-\n  dat_obs_f3 |>\n  left_join(dat_surv) |> \n  rename(species = species_name,\n          decimallongitude = longitude,\n          decimallatitude = latitude) |>\n  CoordinateCleaner::cc_outl(value = \"flagged\")\n\n  dat_obs_f3 |>\n    left_join(dat_surv) |>\n    mutate(good_geog = vals) |>\n    write_csv(file_name)\n}\n\nfile_name |> read_csv()\n\n# A tibble: 15,050,191 x 11\n   survey_id species_~1 size_~2 site_~3 ecore~4 latit~5 longi~6 depth survey_d~7\n       <dbl> <chr>        <dbl> <chr>   <chr>     <dbl>   <dbl> <dbl> <date>    \n 1   2000854 Achoerodu~    50   SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 2   2000854 Achoerodu~    62.5 SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 3   2000854 Achoerodu~   112.  SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 4   2000854 Aplodacty~    15   SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 5   2000854 Aplodacty~    20   SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 6   2000854 Atypichth~     2.5 SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 7   2000854 Atypichth~     2.5 SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 8   2000854 Atypichth~     2.5 SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n 9   2000854 Atypichth~     2.5 SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n10   2000854 Atypichth~     2.5 SYD54   Mannin~   -33.8    151.   6.5 2009-06-27\n# ... with 15,050,181 more rows, 2 more variables: survey_year <dbl>,\n#   good_geog <lgl>, and abbreviated variable names 1: species_name,\n#   2: size_class, 3: site_code, 4: ecoregion, 5: latitude, 6: longitude,\n#   7: survey_date\n\n\n\ngeog_outliers <- \n  \"output/data/error_checking/geography/geog_outliers.csv\" |> \n  read_csv() |> \n  filter(!good_geog) |> \n  mutate(spp_lat_lon = paste(species_name, \n                              latitude, \n                              longitude, \n                              sep = \"_\"))\n\ndat_obs_f3_hasgeogoutliers <- \n  dat_obs_f3 |> \n  left_join(dat_surv) |> \n  mutate(spp_lat_lon = paste(species_name, \n                              latitude, \n                              longitude, \n                              sep = \"_\")) |> \n  filter(spp_lat_lon %in% geog_outliers$spp_lat_lon) |> \n  select(-spp_lat_lon) |> \n  left_join(geog_outliers |> \n              select(species_name, \n                     latitude, \n                     longitude) |> \n              mutate(geog_outlier = TRUE))\n\n\n\nfor(i in unique(dat_obs_f3_hasgeogoutliers$species_name)){\n\n  file_name <- paste0(\"output/figs/error_checking/geography/\",\n                      i,\n                      \".png\")\n  if(!file.exists(file_name)){\n\n    plot_dat <-\n      dat_obs_f3 |>\n      filter(species_name == i) |>\n      left_join(dat_surv) |>\n      count(species_name, latitude, longitude)\n\n    map_plot <-\n      ozmap(x = \"country\") |>\n      ggplot() +\n      geom_sf() +\n      coord_sf() +\n      geom_point(\n        aes(\n          x = longitude,\n          y = latitude,\n          size = n\n        ),\n        pch = 21,\n        col = \"red\",\n        data = plot_dat\n      ) +\n      scale_size_continuous(name = \"# individuals\",\n                            trans = \"log10\",\n                            label = label_number(scale_cut = cut_short_scale())) +\n\n      theme_void() +\n      theme(legend.position = c(0.3, 0.5),\n            legend.justification = c(0.5, 0.5),\n            plot.title = element_text(hjust = 0.5))\n\n    n_indiv <-\n      sum(plot_dat$n) |>\n      as.numeric() |>\n      round(1) |>\n      format(nsmall = 0,\n             big.mark = \",\")\n\n    url_vector <-\n      paste0(\"https://reeflifesurvey.com//species/\",\n             i |>\n             tolower() |>\n             str_replace_all(\" \", \"-\")) |>\n      read_html() |>\n      html_elements(\"img\") |>\n      html_attr(\"src\")\n\n    if(sum(url_vector |> str_detect(\"species_\"))){\n      hasimage <- 1\n      myimage <-\n        url_vector[url_vector |> str_detect(\"species_\")][1] |>\n        image_read()\n    } else {\n      hasimage <- 0\n    }\n\n    basic_plot <- map_plot\n\n    xrange <- layer_scales(basic_plot)$x$range$range\n    yrange <- layer_scales(basic_plot)$y$range$range\n\n    p2 <-\n      map_plot +\n      labs(caption = \"Geographic species distribution\",\n           title = paste0(i, \" (n = \", n_indiv, \")\")) +\n      {if(hasimage)      annotation_raster(myimage,\n                                           xrange[2]-((xrange[2]-xrange[1])*0.2)- (xrange[2]-xrange[1])*.35,\n                                           xrange[2]- (xrange[2]-xrange[1])*.35,\n                                           yrange[2]-((yrange[2]-yrange[1])*0.2)- (yrange[2]-yrange[1])*.4,\n                                           yrange[2] - (yrange[2]-yrange[1])*.4)}\n\n    ggsave(filename = file_name,\n           plot = add_density_margin(p2),\n           height = 15,\n           width = 30,\n           units = \"cm\")\n\n\n  }\n}"
  },
  {
    "objectID": "model_fitting.html",
    "href": "model_fitting.html",
    "title": "Model fitting",
    "section": "",
    "text": "We want to fit a single model to all species, we want this model to test the Giometto hypothesis, that all species can be described by a single body size shape, that is determined by a single parameter, the mean body size of the species.\nThe lognormal distribution can be written as:\n\\[\nl \\sim \\mathcal{LN}(\\mu, \\sigma)\n\\]\nthis is equivalent to:\n\\[\nlog(l) \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\nwe want a distribution of individuals, i, belonging to species, k, can be written as:\n\\[\nl_{k, i} \\sim \\mathcal{LN}(\\mu_k, \\sigma_k)\n\\]\nbut within each species, we can have spatial, s, and temporal, t, variation in these parameters\n\\[\nl_{ki} \\sim \\mathcal{LN}(\\mu_{kst}, \\sigma_{kst})\n\\]\nwe can define \\(\\mu_{kst}\\) as:\n\\[\n\\mu_{kst} = \\mu + \\beta^\\mu_t \\mu + \\beta^\\mu_s \\mu + \\beta^\\mu_k \\mu\n\\]\nand \\(\\sigma_{kst}\\) as:\n\\[\n\\sigma_{kst} = \\sigma + \\beta^\\sigma_t \\sigma + \\beta^\\sigma_s \\sigma + \\beta^\\sigma_k \\sigma\n\\]\nsimilarly we could instead define \\(\\sigma_{kst}\\) as a function of \\(\\mu_{kst}\\)\n\\[\n\\sigma_{kst} = (\\beta_1 \\mu_{kst} + \\beta_2) + \\beta^{\\sigma}_t \\sigma + \\beta^{\\sigma}_s \\sigma + \\beta^{\\sigma}_k \\sigma\n\\]\nIf Giometto’s hypothesis is correct, we would expect \\(\\sigma_{kst}\\) could be fully explained by \\(\\mu_{kst}\\), i.e.:\n\\[\n\\beta_1 \\neq 0 \\\\\n\\beta_2 \\neq 0 \\\\\n\\beta^\\sigma_t = 0 \\\\\n\\beta^\\sigma_s = 0 \\\\\n\\beta^\\sigma_k = 0\n\\]"
  }
]